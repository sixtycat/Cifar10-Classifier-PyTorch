{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#os.chdir(\"/datasets/CIFAR-10\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "trainset = torchvision.datasets.CIFAR10(root='/datasets/CIFAR-10',\n",
    "                                        train=True,\n",
    "                                        download=False)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, num_workers=2)\n",
    "\n",
    "data_orig = trainloader.dataset.train_data\n",
    "num_data = data_orig.shape[0]\n",
    "print(data_orig.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
    "])\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root = '/datasets/CIFAR-10',\n",
    "                                        train = True,\n",
    "                                       download = True,\n",
    "                                       transform = transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset,\n",
    "                                          batch_size = batch_size,\n",
    "                                          shuffle = True,\n",
    "                                          num_workers = 2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root = '/datasets/CIFAR-10',\n",
    "                                          train = False,\n",
    "                                          download = True,\n",
    "                                          transform = transform)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset,\n",
    "                                        batch_size = batch_size,\n",
    "                                        shuffle = False,\n",
    "                                        num_workers = 2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "500\n"
     ]
    }
   ],
   "source": [
    "data_orig = testloader.dataset.test_data\n",
    "num_data = data_orig.shape[0]\n",
    "print(num_data)\n",
    "print(len(trainloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### build net\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as nninit\n",
    "\n",
    "class CNN_net(nn.Module):\n",
    "    def __init__(self, front_layer = [(32,),'M',(64,),(64,),(128,),'M'],\n",
    "                 class_num = 10,\n",
    "                 back_method = 'FCN',\n",
    "                 use_BN = True\n",
    "                 ):\n",
    "        super(CNN_net, self).__init__()\n",
    "        \n",
    "        self.class_num = class_num\n",
    "        self.back_method = back_method\n",
    "        self.use_BN = use_BN\n",
    "        \n",
    "        self.front_process = self.make_cnn_layers(front_layer,\n",
    "                                              batch_norm = True)\n",
    "        if self.back_method == 'FCN':\n",
    "            if self.use_BN:\n",
    "                self.back_process = nn.Sequential(\n",
    "                                    nn.Linear(8*8*front_layer[-2][0], 3000),\n",
    "                                    nn.BatchNorm1d(3000),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Linear(3000,400),\n",
    "                                    nn.BatchNorm1d(400),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Linear(400,10))\n",
    "            else:\n",
    "                self.back_process = nn.Sequential(\n",
    "                                    nn.Linear(8*8*front_layer[-2][0], 3000),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Linear(3000,400),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Linear(400,10))\n",
    "            \n",
    "        else:\n",
    "            raise Exception('Wrong back layer methods')\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.front_process(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.back_process(x)\n",
    "        return x\n",
    "        \n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            nninit.xavier_normal_(m.weight, gain = 1)\n",
    "            nninit.constant_(m.bias, 0)\n",
    "\n",
    "    def make_cnn_layers(self, cfg, batch_norm=True):\n",
    "\n",
    "        '''\n",
    "        The input should be a list, the elements should be tuples. \n",
    "        based on pytorch docs:\n",
    "        Parameters:\n",
    "            in_channels (int) – Number of channels in the input image\n",
    "            out_channels (int) – Number of channels produced by the convolution\n",
    "            kernel_size (int or tuple) – Size of the convolving kernel\n",
    "            stride (int or tuple, optional) – Stride of the convolution. Default: 1\n",
    "            padding (int or tuple, optional) – Zero-padding added to both sides of the input. Default: 1\n",
    "            dilation (int or tuple, optional) – Spacing between kernel elements. Default: 1\n",
    "            groups (int, optional) – Number of blocked connections from input channels to output channels. Default: 1\n",
    "            bias (bool, optional) – If True, adds a learnable bias to the output. Default: True\n",
    "\n",
    "        For convolution layers, the order is:\n",
    "        (out_channels (int), kernel_size (int or tuple, optional, default = 3), \n",
    "        stride (int or tuple, optional), padding (int or tuple, optional), dilation (int or tuple, optional))\n",
    "        if input is less than 0 (ie. -1) then will use default value.\n",
    "\n",
    "        For maxpooling layer:\n",
    "        'M', if need more argument, modify as needed.\n",
    "\n",
    "        5/3/2018 C.\n",
    "\n",
    "        '''\n",
    "        layers = []\n",
    "        in_channels = 3\n",
    "        for v in cfg:\n",
    "\n",
    "            if v[0] == 'M':\n",
    "                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "\n",
    "            elif v[0] == 'I':\n",
    "                in_channels = v[1]\n",
    "\n",
    "            else:\n",
    "                v_len = len(v)\n",
    "                ker_size = 3\n",
    "                stride_val = 1\n",
    "                padding_val = 1\n",
    "                dialtion_val = 1\n",
    "\n",
    "                out_channels = v[0]\n",
    "                if v_len >= 2:\n",
    "                    if v[1] > 0:\n",
    "                        ker_size = v[1]\n",
    "                    if v_len >= 3:\n",
    "                        if v[2] > 0:\n",
    "                            stride_val = v[2]\n",
    "                        if v_len >= 4:\n",
    "                            if v[3] > 0:\n",
    "                                padding_val = v[3]\n",
    "                            if v_len >= 5:\n",
    "                                if v[4] > 0:\n",
    "                                    dialtion_val = v[4]\n",
    "\n",
    "\n",
    "                conv2d = nn.Conv2d(in_channels, out_channels, kernel_size = ker_size, stride = stride_val,\n",
    "                                   padding = padding_val, dilation = dialtion_val)\n",
    "                if batch_norm:\n",
    "                    layers += [conv2d, nn.BatchNorm2d(v[0]), nn.ReLU(inplace=True)]\n",
    "                else:\n",
    "                    layers += [conv2d, nn.ReLU(inplace=True)]\n",
    "                in_channels = v[0]\n",
    "        return nn.Sequential(*layers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_accu(dataloader):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for i, data in enumerate(dataloader):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device),labels.to(device)\n",
    "        outputs = net0(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    return 100 * correct / total\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trianing model with RMSprop_Momentum=0.9_back_layers=FCN_BN=True\n",
      "CNN_net(\n",
      "  (front_process): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (2): ReLU(inplace)\n",
      "    (3): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1), ceil_mode=False)\n",
      "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (6): ReLU(inplace)\n",
      "    (7): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (9): ReLU(inplace)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (12): ReLU(inplace)\n",
      "    (13): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1), ceil_mode=False)\n",
      "  )\n",
      "  (back_process): Sequential(\n",
      "    (0): Linear(in_features=16384, out_features=3000, bias=True)\n",
      "    (1): BatchNorm1d(3000, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=3000, out_features=400, bias=True)\n",
      "    (4): BatchNorm1d(400, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=400, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c4a4ac2d038476c80fbcefbe0abf636",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=20), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch is  1\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "argument 0 is not a Variable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-e536a684bd1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-03f737d62a3e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfront_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mback_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 282\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mconv2d\u001b[0;34m(input, weight, bias, stride, padding, dilation, groups)\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0m_pair\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbenchmark\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m                 torch.backends.cudnn.deterministic, torch.backends.cudnn.enabled)\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: argument 0 is not a Variable"
     ]
    }
   ],
   "source": [
    "### loss function may calculate wrong in this cell\n",
    "### May need to modify.\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import torch.optim as optim\n",
    "\n",
    "optim_model = 'RMSprop' # 'SGD' ; 'Adagrad' ; 'RMSprop'\n",
    "use_Nest = False\n",
    "momentum_val = 0.9\n",
    "back_method = 'FCN'\n",
    "use_BN = True\n",
    "learn_rate = 0.001\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('device is ',device)\n",
    "'''\n",
    "For convolution layers, the order is:\n",
    "        (out_channels (int), kernel_size (int or tuple, optional, default = 3), \n",
    "        stride (int or tuple, optional), padding (int or tuple, optional), dilation (int or tuple, optional))\n",
    "        if input is less than 0 (ie. -1) then will use default value.\n",
    "\n",
    "        For maxpooling layer:\n",
    "        'M', if need more argument, modify as needed.\n",
    "\n",
    "'''\n",
    "CNN_cfg = [[(32,),'M',(64,),(64,),(128,),'M'],\n",
    "           [(32,),'M',(64,),(64,),(128,),(128,),'M'],\n",
    "           [(64,),'M',(128,),(128,5,-1,2),(256,),'M']]\n",
    "\n",
    "\n",
    "net0 = CNN_net(CNN_cfg[2],\n",
    "             class_num = 10,\n",
    "             back_method = back_method,\n",
    "             use_BN = use_BN)\n",
    "\n",
    "net0.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "if optim_model == \"SGD\":\n",
    "    optimizer = optim.SGD(net0.parameters(), lr = learn_rate, momentum = momentum_val, nesterov= use_Nest)\n",
    "    model_type = optim_model + '_Nest=' + str(use_Nest) + '_Momentum=' + str(momentum_val) + '_back_layers='\\\n",
    "        + back_method + '_BN=' + str(use_BN)\n",
    "        \n",
    "elif optim_model == 'Adagrad':\n",
    "    optimizer = optim.Adagrad(net0.parameters(), lr = learn_rate)\n",
    "    model_type = optim_model + '_back_layers='\\\n",
    "        + back_method + '_BN=' + str(use_BN)\n",
    "    \n",
    "elif optim_model == 'RMSprop':\n",
    "    optimizer = optim.RMSprop(net0.parameters(), lr = learn_rate, momentum = momentum_val)\n",
    "    model_type = optim_model + '_Momentum=' + str(momentum_val) + '_back_layers='\\\n",
    "        + back_method + '_BN=' + str(use_BN)\n",
    "    \n",
    "else:\n",
    "    raise Exception('Wrong optimizer')\n",
    "\n",
    "\n",
    "epoch_m = 20\n",
    "\n",
    "loss_train = []\n",
    "loss_train_mini = []\n",
    "loss_test = []\n",
    "\n",
    "accu_train = []\n",
    "accu_test = []\n",
    "\n",
    "print('Trianing model with ' + model_type)\n",
    "print(net0)\n",
    "\n",
    "for epoch in tqdm(range(1, epoch_m + 1)):\n",
    "    print('Epoch is ', epoch)\n",
    "    for i, data in enumerate(trainloader,0):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device),labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = net0(inputs)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    loss_train.append(loss.item() / batch_size)\n",
    "    accu_train.append(cal_accu(trainloader))\n",
    "    \n",
    "    print('training loss', loss_train[-1])\n",
    "    print('training accuracy', accu_train[-1])\n",
    "    \n",
    "    for j, data in enumerate(testloader):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device),labels.to(device)\n",
    "        \n",
    "        outputs = net0(inputs)\n",
    "        loss += criterion(outputs, labels).item()\n",
    "        \n",
    "    loss_test.append(loss.item() / (batch_size * len(testloader)))\n",
    "    accu_test.append(cal_accu(testloader))\n",
    "    \n",
    "    print('test loss', loss_test[-1])\n",
    "    print('test accuracy', accu_test[-1])\n",
    "        \n",
    "print('finished')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.3.1.post3'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "title_accu = 'Accuracy with ' + model_type\n",
    "title_loss = 'Loss with ' + model_type\n",
    "        \n",
    "\n",
    "plt.figure(figsize=(5.5,4))\n",
    "plt.clf()\n",
    "plt.plot(list(range(1, len(loss_train) + 1)),loss_train)\n",
    "plt.plot(list(range(1, len(loss_train) + 1)),loss_test)\n",
    "plt.xlabel('Epoch',fontsize= 11)\n",
    "plt.ylabel('Loss',fontsize= 11)\n",
    "plt.title(title_loss,fontsize= 11)\n",
    "plt.legend(['Training loss','Valid loss'],fontsize= 11)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(5.5,4))\n",
    "plt.clf()\n",
    "plt.plot(list(range(1, len(accu_train) + 1)),accu_train)\n",
    "plt.plot(list(range(1, len(accu_train) + 1)),accu_test)\n",
    "plt.xlabel('Epoch',fontsize= 11)\n",
    "plt.ylabel('Accuracy',fontsize= 11)\n",
    "plt.title(title_accu,fontsize= 11)\n",
    "plt.legend(['Training accuracy','Valid accuracy'],fontsize= 11)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
